\documentclass[twoside,11pt]{article} 
\usepackage{jmlr2e} 
\usepackage{hyperref}
\jmlrheading{1}{2011}{1-48}{4/00}{10/00}{Pedregosa, Varoquaux et al.}

% Short headings should be running head and authors last names

\usepackage{xcolor}
\usepackage[normalem]{ulem}

\newcommand{\GAEL}[1]{\textcolor{blue}{\uline{#1}}}
\newcommand{\FABIAN}[1]{\textcolor{red}{\uline{#1}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\ShortHeadings{scikits.learn: machine learning in Python}{Pedregosa, Varoquaux et al.}
\firstpageno{1}


\begin{document}

\title{scikits.learn: machine learning in Python}


\author{\name Fabian Pedregosa \email fabian.pedregosa@inria.fr \\
        \name Gael Varoquaux \email gael.varoquaux@normalesup.org  \\
        \name Alexandre Gramfort \email TODO (INRIA?)\\
        \name Vincent Michel  \email TODO \\
       \addr  Neurospin, Bâtiment 145\\
       point courier 156, CEA Saclay\\
       91191 Gif sur Yvette – FRANCE
       \AND
       \name Olivier Grisel \email jordan@cs.berkeley.edu \\
       \addr Division of Computer Science and Department of Statistics\\
       University of California\\
       Berkeley, CA 94720-1776, USA
       \AND
       \name MANY MORE
}


\editor{?}

\maketitle

\begin{abstract}
This paper describes \emph{scikits.learn}, a Python module integrating
a wide range of state-of-the-art machine learning algorithms for
medium-scale supervised and unsupervised problems. 


It focuses on bringing machine learning to non-specialists using a
general-purpose high-level language with special care on documentation
and clean API.

The large number of algorithms aleady implemented allows for easy
comparison of prediction and numerical performance of algorithms on a
given application.


scikits.learn is licensed under the simplified BSD license,
encouraging its use in both free and commercial settings. Soruce code
and documentation can be downloaded from
\url{http://scikit-learn.sourceforge.net}.

\end{abstract}

but I don't think that when 

\keywords{Python, supervised learning, unsupervised learning}


%%  It offers a wide range of
%% methods such as Support Vector Machines, linear models (L1, L2
%% penalized), logistic regression, gaussian mixture models and more.


\section{Introduction}
In the past years the Python programming language has experienced a
huge increase as the language of choice for scientific computing. Its
high level, general-purpose, interactive nature and its maturing
ecosystem of of scientific libraries (numpy, scipy, matplotlib) [CITE
  MARS 2011 CiSE] make it a very appealing choice for both research
and industry.


This motivated us to develop scikits.learn, a module that implements a
broad range of machine learning algorithms under a Pythonic
interface. While several other machine learning toolkits implement
most of their code in C/C++ and provide Python bindings, we write as
much code as possible in Python, and code performance-critical blocks
in C or Cython. TODO: advantages of this. Too soon for this (maybe
should go into Project vision)?


The API has been kept as simple as possible, making it easy to
implement new algorithms and improve old ones. The large number of
algorithms aleady implemented allows for easy comparison of accuracy
and performance of various algorithms.

--> NO FRAMEWORK, design by convention

strives for easy of use by using plain np arrays instead of specialized
data structures and limiting framework code.

% std libraries like libsvm

\section{Project vision}

\begin{center}
%% \caption{Overview of existing machine learning libraries}

% it would be nicer with checkbox images

\begin{tabular}{c c c c c c c}
\hline\hline %inserts double horizontal lines 
implements & scikits.learn & mlpy & pybrain & pymvpa &  mdp & shogun \\ [0.5ex]
\hline
Support Vector Machines        & + & ?   & ?       &  ?     & ?    & + \\
Elastic Net & + & ?   & ?       &  ?     & ?    & - \\
Gaussian Mixture Models  & + & ?   & ?       &  ?     & ?    & - \\
k-Nearest Neighbors & + & ?   & ?       &  ?     & ?    & - \\
Independent Component Analysis & + & ?   & ?       &  ?     & ?    & - \\
Usable in commercial code &  + & -   & +       &  +     & +    & - \\
\hline
\end{tabular}
\GAEL{Plutot que des croix, mettre des timings sur des tests canoniques (à 
définir, mais cela serait sur les donnees canoniques). Rajouter kNN, et
ICA ou kmeans.}\\
\FABIAN{How to indent text to the left ?}
\end{center}


Key technologies include numpy and cython. Numpy arrays are the choice for
representing data. Numpy is the universal format for representing
arrays, all methods accept dense or sparse numpy arrays on entry, and
it is also easy to convert and load numpy arrays from existing formats:
.mat, csv, gzip, etc.

The purpose of Cython is twofold. First, it allows to reach the
performance of traditional compiled languages as C while retaining
some of the benefits of Python, such as clear syntax and garbage
collection.

Second, Cython allows to easily access third-party libraries. libsvm
and liblinear have been efficiently binded using Cython [...]. Special
care has been taken in this step, effectively reducing the overhead of
Python/C communication and yelding memory and speed effective bindings.


\section{Computational efficiency tradeoffs}

|| BENCKMARK IMAGE ||


Special care is taken in the algorithmic efficiency. Least Angle
regression uses smart reordering of computations, and achieves 10x to
2x performance improvements over the reference implementation, the R
pakcage LARS. Also, fast KNN in high-dimensional spaces is achieved
using the BallTree algorithm.

|| BENCH ||

\section{Code design}

\paragraph{Code by interface, not by inheritance}
%
We adopt simple conventions and limit the number of methods an object
has to implement. In its simples form, a classifier is an object that
implements a \emph{fit} and \emph{predict} method. Inheritance is not
enforced, and any classifier implementing these methods is able to
plug in the scikits.learn framework.


More spcialized classifiers might implement other methods as
well. Filters are objects that implement a \emph{transform} method,
and serve for feature selection.

\GAEL{The word filter is often used in ML for specific kind of
transformations. We should refrain from using it. In the scikit we now
call these objects 'Transforms'. }

\GAEL{Speak here about API for unsupervised problems: score, transform and
predict can be useful to give an application-centric meaning to
unsupervised models.}

\paragraph{Model selection}

\GAEL{Speak of the model-selection framework: GridSearch and Pipeline
objects, but also the different 'XXXCV' objects, and why they are needed
(for numerical performance)}

\section{Community-driven development}

\GAEL{Probably shouldn't be a full section, maybe in the conclusion, or
in the vision}

Special care has been taken to encourage external contributions. First
of, every significant function is documented and tested. In fact,
Ohloh, the open source directory, describes the project as
``Well-commented source code'' and ``Very large, active development
team''.

\GAEL{Speak of coding standards, and testing} 

Also, a precise instructions on how to contribute as well as coding
guidelines make contributing code easy and efficient process. 28
developers contributed code over the last twelve months.

We have succesfully used this software to real-world problems. Some
applications can be seen in the online gallery, featuring more than 60
examples.


\section{Drawnbacks}

\GAEL{Probably shouldn't be a full section, maybe in the conclusion}

While the choice of Python ensoures code reuse in the package, it also
binds us to this language and limits its use outside the Python
language.

This effectively rules out code sharing with other major scientific
platforms, such as MATLAB©, Octace, and R.


\section{Conclusions}

bla bla.

\end{document}
