\documentclass[twoside,11pt]{article} 
\usepackage{jmlr2e} 
\usepackage{hyperref}
\jmlrheading{1}{2011}{1-48}{4/00}{10/00}{Pedregosa, Varoquaux et al.}

% Short headings should be running head and authors last names

\usepackage{xcolor}
\usepackage[normalem]{ulem}

\newcommand{\GAEL}[1]{\textcolor{blue}{\uline{#1}}}
\newcommand{\FABIAN}[1]{\textcolor{red}{\uline{#1}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\ShortHeadings{scikits.learn: machine learning in Python}{Pedregosa, Varoquaux et al.}
\firstpageno{1}


\begin{document}

\title{scikits.learn: machine learning in Python}


\author{\name Fabian Pedregosa \email fabian.pedregosa@inria.fr \\
        \name Gael Varoquaux \email gael.varoquaux@normalesup.org  \\
        \name Alexandre Gramfort \email alexandre.gramfort@inria.fr \\
        \name Vincent Michel  \email vincent.michel@inria.fr \\
        \name Bertrand Thirion  \email bertrand.thirion@inria.fr \\
        \addr  Neurospin, B\^atiment 145\\
        point courier 156, CEA Saclay\\
        91191 Gif sur Yvette – FRANCE
        \AND
        \name Olivier Grisel \email olivier.grisel@ensta.fr \\
        \addr Nuxeo \\
        \\
        \AND
        \name MANY MORE
}


\editor{?}

\maketitle

\begin{abstract}
This paper describes \emph{scikits.learn}, a Python module integrating
a wide range of state-of-the-art machine learning algorithms for
medium-scale supervised and unsupervised problems. This package
focuses on bringing machine learning to non-specialists using a
general-purpose high-level language with special care on ease of use,
documentation and consistent API.


scikits.learn is licensed under the simplified BSD license,
encouraging its use in both free and commercial settings. Soruce code
and documentation can be downloaded from
\url{http://scikit-learn.sourceforge.net}.

\end{abstract}

\keywords{Python, supervised learning, unsupervised learning}


%%  It offers a wide range of
%% methods such as Support Vector Machines, linear models (L1, L2
%% penalized), logistic regression, gaussian mixture models and more.


\section{Introduction}
In the past years the Python programming language has experienced a
huge increase as the language of choice for scientific computing. Its
high level, interactive nature and its maturing ecosystem of
scientific libraries (numpy, scipy, matplotlib) [Mars 2011 CiSE]
make it a very appealing choice for both research and industry.


%% We have also found it to be a convenient vector of communication with
%% the non-specialist. Users can use an interactive, easy-to-learn,
%% general-purpose language and have access to state-of-the-art
%% scientific software.

%% In a context such as
%% machine learning where state-of-the art methods are routinely used by
%% non-specialist.

This motivated us to develop scikits.learn, a module with the goal of
providing an efficient implementation of state-of-the-art machine
learning algorithms for the Python language. The project was started
in January 2010, and after just one year of intensive development,
more than 40 algorithms ranging from supervised to unsupervised
learning have already been implemented, providing an unequal framework
for easily comparison of different methods on a given application.


We firmly believe that documentation is the single most important part
of a software distribution, and as such scikits.learn includes a ~300
page user guide with narrative documentation, class reference,
tutorial, installation instructions as well as a collection of more
than 60 examples, some of them featuring real-world applications of
the library.


The package has only numpy and scipy as strict dependences, which
ensure it's availability in a rich set of platforms. scikits.learn
runs on Windows and POSIX platforms. Furthermore, it is distributed as
part of major open source distributions such as Ubuntu, Debian, NetBSD
or Macports and in commercial distributions such as ``Enthought Python
Distribution'' thanks to its liberal BSD license.

% std libraries like libsvm

\section{Project vision}

SOMETHING

An important aspect in the design of scikits.learn was to make
extensive use of existing python scientific libraries such as numpy
and scipy. This allow for maximum code reuse and reducing the
deployment cost of library availability in the host platform.

Numpy is used for fast array manipulation, and provide the base data
structure for representing information. This choice strives for easy
of use by using plain np arrays instead of specialized data structures
and limiting framework code.


%% All methods accept dense or
%% sparse numpy arrays on entry, and it is also easy to convert and load
%% numpy arrays from existing formats: .mat, csv, gzip, etc.


The purpose of Cython is twofold. First, it allows to reach the
performance of compiled languages as C while retaining some of the
benefits of Python, as clear syntax and garbage collection.

Second, Cython allows to easily access third-party libraries. libsvm
and liblinear have been efficiently wrapped using Cython [...]. Special
care has been taken in this step, effectively reducing the overhead of
Python/C communication and yielding memory and speed effective bindings.

%% what sets us apart from many other machine learning toolboxes, is
%% that ...



\begin{center}
%% \caption{Overview of existing machine learning libraries}

% it would be nicer with checkbox images

\begin{tabular}{l c c c c c c}
\hline\hline %inserts double horizontal lines 
 & scikits.learn & mlpy & pybrain & pymvpa &  mdp & shogun \\ [0.5ex]
\hline
Support Vector Machines        & 0.0 & 0.0   & 0.0       &  0.0     & 0.0    & 0.0 \\
Elastic Net & 0.0 & 0.0   & 0.0       &  0.0     & 0.0    & - \\
Gaussian Mixture Models  & 0.0 & 0.0   & 0.0       &  0.0     & 0.0    & - \\
k-Nearest Neighbors & 0.0 & 0.0   & 0.0       &  0.0     & 0.0    & - \\
Indep. Component Analysis & 0.0 & 0.0  & 0.0  & 0.0  & 0.0  & - \\
ANN  & - & 0.0  & 0.0  & 0.0  & 0.0  & - \\
Usable in commercial code &  0.0 & -   & 0.0       &  0.0     & 0.0    & - \\
\hline
\end{tabular}
\GAEL{Plutot que des croix, mettre des timings sur des tests canoniques (à 
définir, mais cela serait sur les donnees canoniques). Rajouter kNN, et
ICA ou kmeans.}\\

\end{center}


\section{Computational efficiency tradeoffs}

|| BENCKMARK IMAGE ||


Special care has been take on algorithmic efficiency, producing
algorithms that are ofter faster than the ones found in compiled
libraries.



Least Angle Regression, is implemented in pure Python and achieve 10x
to 2x gain in performance over the reference implementation, the R
package LARS, by smarter updates of coefficients [rephrase].


The elasticnet algorithm, by coordinate descent, coded in Cython
achieves the same order of performance as the highly optimized Fortran
version elasticnet.

Also, fast KNN in high-dimensional spaces is achieved using the
BallTree algorithm (C++).

|| BENCH ||

\section{Code design}

\paragraph{Code by interface, not by inheritance}
%
We adopt simple conventions and limit the number of methods an object
has to implement. In its simples form, a classifier is an object that
implements a \emph{fit} and \emph{predict} method. Inheritance is not
enforced, and any classifier implementing these methods is able to
plug in the scikits.learn framework.


More spcialized classifiers might implement other methods as
well. Filters are objects that implement a \emph{transform} method,
and serve for feature selection.

\GAEL{The word filter is often used in ML for specific kind of
transformations. We should refrain from using it. In the scikit we now
call these objects 'Transforms'. }

\GAEL{Speak here about API for unsupervised problems: score, transform and
predict can be useful to give an application-centric meaning to
unsupervised models.}

\paragraph{Model selection}

\GAEL{Speak of the model-selection framework: GridSearch and Pipeline
objects, but also the different 'XXXCV' objects, and why they are needed
(for numerical performance)}

Model selection is performed by GridSearchCV (Pipeline)

However, some properties in the algorithms (warm restarts, path
solutions, etc.) can, and should be used be used to speed up the
process. To allow this The methods are model-dependent and are
implemented in classes that append ``CV'', for cross-validation, to
the model name (Lasso and LassoCV, etc.)


\section{Community-driven development}

\GAEL{Probably shouldn't be a full section, maybe in the conclusion, or
in the vision}

Special care has been taken to encourage external contributions. First
of, every significant function is documented and tested.  Ohloh, the
open source directory, describes the project as ``Well-commented
source code'' and ``Very large, active development team''.

\GAEL{Speak of coding standards, and testing} 

Also, a precise instructions on how to contribute as well as coding
guidelines make contributing code easy and efficient process. 28
developers contributed code over the last twelve months.

We have succesfully used this software to real-world problems. Some
applications can be seen in the online gallery, featuring more than 60
examples.



\section{Conclusions}

bla bla.

While the choice of Python ensoures code reuse in the package, it also
binds us to this language and limits its use outside the Python
language.

This effectively rules out code sharing with other major scientific
platforms, such as MATLAB©, Octave, and R.

\end{document}
